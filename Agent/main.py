import json
from pprint import pprint

from src.llm.openai_client import OpenAIClient
from src.agent.prompts.search_company_info_prompt import CompanyInfoPrompt
from src.agent.tools.tool_registry import TOOLS


# SYSTEM_PROMPT = """
# í•œê¸€ë§ë¡œ ë“¤ì–´ì˜¤ë©´ ì˜ì–´ë¡œ ë²ˆì—­í•´ì„œ ì²˜ë¦¬í•´ì¤˜ í•˜ì§€ë§Œ ë‹µë³€ì€ ë¬´ì¡°ê±´ í•œêµ­ë§ë¡œ ë²ˆì—­í•´ì„œ ë‹µë³€í•´ì¤˜ ìµœëŒ€í•œ ì‚¬ëŒì´ ëŒ€í™”í•œê²ƒ ì²˜ëŸ¼ ì¹œê·¼ê° ìˆê²Œ ë‹µë³€ í•´ì¤˜.
# ê·¸ë¦¬ê³  ë¬´ì¡°ê±´ ì •í•´ì§„ Toolì„ ì´ìš©í•´ì„œ ë‹µë³€ì„ ë§Œë“¤ì–´ì„œ ëŒë ¤ì¤˜
# """

class StockResearchAgent:
    def __init__(self):
        self.llm = OpenAIClient(model="gpt-4o")
        self.tools = [tool.schema() for tool in TOOLS]
        self.tool_map = {tool.name: tool for tool in TOOLS}
        self.messages = []

    def __str__(self):
        return "StockResearchAgent using tools: " + ", ".join([tool.name for tool in TOOLS])

    def process(self, **kwargs):
        while True:
            user_input = input("ê¶ê¸ˆí•œ ì£¼ì‹ ì •ë³´ ë¬¼ì–´ë³´ì„¸ìš”: ").strip()
            if user_input.lower() in {"exit", "quit", "ì•ˆë…•", "ì¢…ë£Œ"}:
                print("Bye ğŸ‘‹")
                break

            self.messages = [
                {"role": "system", "content": CompanyInfoPrompt.search_company_info_prompt},
                {"role": "user", "content": user_input}
            ]

            try:
                # 1ï¸âƒ£ ì²« LLM í˜¸ì¶œ (tool ì„ íƒ)
                response = self.llm.chat(self.messages, tools=self.tools)

                # 2ï¸âƒ£ tool í˜¸ì¶œ ì²˜ë¦¬
                if response.tool_calls:
                    # ğŸ”¥ 1. assistant ë©”ì‹œì§€ë¥¼ ë¨¼ì € ì¶”ê°€
                    self.messages.append({
                        "role": "assistant",
                        "content": response.content,
                        "tool_calls": [
                            {
                                "id": call.id,
                                "type": "function",
                                "function": {
                                    "name": call.function.name,
                                    "arguments": call.function.arguments,
                                }
                            }
                            for call in response.tool_calls
                        ]
                    })

                    # ğŸ”¥ 2. tool ì‹¤í–‰ & tool ë©”ì‹œì§€ ì¶”ê°€
                    for call in response.tool_calls:
                        tool_name = call.function.name
                        tool_args = json.loads(call.function.arguments)

                        tool = self.tool_map[tool_name]
                        result = tool.process(**tool_args)

                        self.messages.append({
                            "role": "tool",
                            "tool_call_id": call.id,
                            "content": json.dumps(result, ensure_ascii=False)
                        })
                    # ğŸ”¥ 3. tool ê²°ê³¼ í¬í•¨í•´ ë‹¤ì‹œ í˜¸ì¶œ
                    response = self.llm.chat(self.messages)

                # 4. ìµœì¢… ê²°ê³¼ë¥¼ ë‹µë³€ìœ¼ë¡œ ì„¤ì •
                self.messages.append({
                    "role": "assistant",
                    "content": response.content
                })

                # 5. ìµœì¢… ë‹µë³€ ì¶œë ¥
                print("\n" + "=" * 50)
                # print(result_response.content)
                print(response.content) # class 'openai.types.chat.chat_completion_message.ChatCompletionMessage'
                print("=" * 50 + "\n")

            except Exception as e:
                print(f"Error during LLM chat: {e}")
                continue


if __name__ == "__main__":
    agent = StockResearchAgent()
    agent.process()