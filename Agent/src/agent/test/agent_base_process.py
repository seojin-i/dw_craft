import json

from src.agent.prompts.search_company_info_prompt import CompanyInfoPrompt

def process(self, **kwargs):
    while True:
        user_input = input("ê¶ê¸ˆí•œ ì£¼ì‹ ì •ë³´ ë¬¼ì–´ë³´ì„¸ìš”: ").strip()
        if user_input.lower() in {"exit", "quit", "ì•ˆë…•", "ì¢…ë£Œ"}:
            print("Bye ğŸ‘‹")
            break

        self.messages = [
            {"role": "system", "content": CompanyInfoPrompt.search_company_info_prompt},
            {"role": "user", "content": user_input}
        ]

        try:
            # 1ï¸âƒ£ ì²« LLM í˜¸ì¶œ (tool ì„ íƒ)
            response = self.llm.chat(self.messages, tools=self.tools)

            # 2ï¸âƒ£ tool í˜¸ì¶œ ì²˜ë¦¬
            if response.tool_calls:
                # ğŸ”¥ 1. assistant ë©”ì‹œì§€ë¥¼ ë¨¼ì € ì¶”ê°€
                self.messages.append({
                    "role": "assistant",
                    "content": response.content,
                    "tool_calls": [
                        {
                            "id": call.id,
                            "type": "function",
                            "function": {
                                "name": call.function.name,
                                "arguments": call.function.arguments,
                            }
                        }
                        for call in response.tool_calls
                    ]
                })

                # ğŸ”¥ 2. tool ì‹¤í–‰ & tool ë©”ì‹œì§€ ì¶”ê°€
                for call in response.tool_calls:
                    tool_name = call.function.name
                    tool_args = json.loads(call.function.arguments)

                    tool = self.tool_map[tool_name]
                    result = tool.process(**tool_args)

                    self.messages.append({
                        "role": "tool",
                        "tool_call_id": call.id,
                        "content": json.dumps(result, ensure_ascii=False)
                    })
                # ğŸ”¥ 3. tool ê²°ê³¼ í¬í•¨í•´ ë‹¤ì‹œ í˜¸ì¶œ
                response = self.llm.chat(self.messages)

            # 4. ìµœì¢… ê²°ê³¼ë¥¼ ë‹µë³€ìœ¼ë¡œ ì„¤ì •
            self.messages.append({
                "role": "assistant",
                "content": response.content
            })

            # 5. ìµœì¢… ë‹µë³€ ì¶œë ¥
            print("\n" + "=" * 50)
            # print(result_response.content)
            print(response.content)  # class 'openai.types.chat.chat_completion_message.ChatCompletionMessage'
            print("=" * 50 + "\n")

        except Exception as e:
            print(f"Error during LLM chat: {e}")
            continue